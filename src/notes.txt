https://en.wikipedia.org/wiki/MeCab
https://towardsdatascience.com/sudachipy-a-japanese-morphological-analyzer-in-python-5f1f8fc0c807

word/sentence segmenter: https://github.com/yanshao9798/segmenter
training data for segmenter: https://universaldependencies.org
aligning words (unsupervised): https://github.com/clab/fast_align
machine translation: http://opennmt.net/

Ideas for improvement:
   - make special rules for the copula (desu)
   - change desu to -pol in places where it is just used as politeness. In the gold data
   - use synonyms of english words
   - add dictionary with names
   - allow translations to be correct as long as they contain the right word?
   - fix scoring
   - do something about w-question + ka
   - fix removal of "to"
   - problems with tokenization, does not seem to take longest match
   - use normalization to make making endings easier
   - use same dictionary for tokenization as translation

performance:
    before adding kana usually:
    6.90
    after:
    6.83

    before matching pos:
    6.86
    after:
    6.82

    before fixing da/desu:
    6.83
    after:
    6.7